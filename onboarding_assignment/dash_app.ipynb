{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f7aac5-a487-46b2-9c2c-40ae0d6e1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc \n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "import dash.dependencies as dd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import MetaData, Table\n",
    "from sqlalchemy import select\n",
    "from io import BytesIO\n",
    "from wordcloud import WordCloud\n",
    "import base64\n",
    "import dash_bootstrap_components as dbc\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6a6272-97e1-4596-8826-1b01943a1085",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load data from databse\n",
    "If there's no connection to the database available, scroll down to find the code to load the data from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa87660a-d56c-4150-b74d-a5d2e5caf43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment = pd.read_csv('sentiment140_uncleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf861c9-f4b1-493e-b377-7b77a90f6c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cleaned data from database\n",
    "engine = create_engine('mysql+pymysql://root:{myPassword}@localhost:3306/{myDatabase}')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f245ddef-4aa6-42bd-a28e-420d5e6c3552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned sentiment140 dataset\n",
    "metadata = MetaData()\n",
    "twitter_data = Table('twitter_data', metadata, autoload=True, autoload_with = engine)\n",
    "stmt = select([twitter_data])\n",
    "result = connection.execute(stmt).fetchall()\n",
    "# create new data frame from dataset\n",
    "df_train_cleaned = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0eebcf-71ff-4742-9f66-799eaa8aa9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get custom dataset from database\n",
    "metadata = MetaData()\n",
    "custom_data = Table('custom_twitter_data', metadata, autoload=True, autoload_with = engine)\n",
    "stmt = select([custom_data])\n",
    "result = connection.execute(stmt).fetchall()\n",
    "custom_test_df_cleaned = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d4ba2-ed26-4dcc-90a3-16249e8c66dd",
   "metadata": {},
   "source": [
    "### Load data from csv-Files\n",
    "Load the data from csv-Files, if there is no connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22952e6f-f8c2-457f-807b-4c98245ba7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment = pd.read_csv('sentiment140_uncleaned.csv')\n",
    "df_train_cleaned = pd.read_csv('train_cleaned.csv')\n",
    "custom_test_df_cleaned = pd.read_csv('customData_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085677a9-6ac7-428d-bfe5-70808fc6f8c4",
   "metadata": {},
   "source": [
    "### Create plots to show in dash\n",
    "run all lines of code to be able to run the dash app later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa5440-3036-441a-a968-1b4adf8a8d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_frequency(corpus):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ec428-e664-4713-a286-c5f3b0422b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cleaned_neg = df_train_cleaned[df_train_cleaned[\"polarity\"] == 0]\n",
    "df_train_cleaned_pos = df_train_cleaned[df_train_cleaned[\"polarity\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276af4b8-09dc-40b0-ab4c-9f90054878f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words_freq= get_words_frequency(df_train_cleaned_pos[\"text\"])\n",
    "neg_words_freq = get_words_frequency(df_train_cleaned_neg[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9942ae2d-d182-4bd5-be85-71cb664911e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_pos_words = pos_words_freq[:50]\n",
    "top_50_neg_words = neg_words_freq[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef3587-f26b-484a-8f7a-f0d79d3592cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top50_pos = pd.DataFrame(top_50_pos_words, columns =['Word', 'Count'])\n",
    "df_top50_neg = pd.DataFrame(top_50_neg_words, columns =['Word', 'Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb9f7a8-6937-4fd8-9fce-b9659ebc22e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distribution of positive and negative tweets in train data set\n",
    "df_train_cleaned_labeled = df_train_cleaned\n",
    "df_train_cleaned_labeled['polarity'] = np.where(df_train_cleaned_labeled['polarity'] == 0, 'Negative tweet', df_train_cleaned_labeled['polarity'])\n",
    "df_train_cleaned_labeled['polarity'] = np.where(df_train_cleaned_labeled['polarity'] == '1', 'Positive tweet', df_train_cleaned_labeled['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2270c7-3b36-4bcc-b896-fd1613cd04fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to run these figures to run the dash app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97900c53-2e7d-428d-960d-570828881ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df_train_cleaned, x=\"polarity\", color='polarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b307465d-ce19-4998-b5f5-d04b525ce6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_top50_pos, x=\"Word\" ,y = \"Count\",title=\"Distribution of the most frequent positive words\", log_y=True)\n",
    "fig.update_layout({'yaxis':{'title':{'text':'Frequency'}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741221fd-c264-4d3e-a99a-8306d96283ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_top50_neg, x=\"Word\" ,y = \"Count\",title=\"Distribution of the most frequent negative words\", log_y=True)\n",
    "fig.update_layout({'yaxis':{'title':{'text':'Frequency'}}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0246f2-605c-43db-85c2-3092ed31826d",
   "metadata": {},
   "source": [
    "## Create wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f4005-1f14-4497-ad74-62c029812b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.DataFrame(pos_words_freq, columns =['Word', 'Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737fb388-91c8-4f89-a2af-074f64ac579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(zip(df_pos['Word'].tolist(), df_pos['Count'].tolist()))\n",
    "data = df_pos.set_index('Word').to_dict()['Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895c596-c94b-4b00-b3cc-6303ce7b7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(width=800, height=400, max_words=200,background_color='white').generate_from_frequencies(data)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig(f'wordcloud_pos.png',\n",
    "            dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786bb27d-4bb6-48bf-9f30-e0dda28543a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg = pd.DataFrame(neg_words_freq, columns =['Word', 'Count'])\n",
    "data_neg = dict(zip(df_neg['Word'].tolist(), df_neg['Count'].tolist()))\n",
    "data_neg = df_neg.set_index('Word').to_dict()['Count']\n",
    "wc_neg = WordCloud(width=800, height=400, max_words=200,background_color='white').generate_from_frequencies(data_neg)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(wc_neg, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig(f'wordcloud_neg.png',\n",
    "            dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38064c0d-6078-45ab-850b-f1789dcb9221",
   "metadata": {},
   "source": [
    "Run this code to create the roc curve and be able to start the dash app!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee6bdb-3cb0-4e20-a1a6-b1f2506a14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute roc curve\n",
    "my_arrays = np.load(\"arrays_for_roc.npz\")\n",
    "fpr_lr = my_arrays[\"arr_0\"]\n",
    "tpr_lr= my_arrays[\"arr_1\"]\n",
    "thresholds= my_arrays[\"arr_2\"]\n",
    "roc_auc_score_lr= my_arrays[\"arr_3\"][0]\n",
    "fpr= my_arrays[\"arr_4\"]\n",
    "tpr= my_arrays[\"arr_5\"]\n",
    "thresholds= my_arrays[\"arr_6\"]\n",
    "roc_auc_score_nb= my_arrays[\"arr_7\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a866af4-c59a-4b18-b8f3-54334a5261ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_fig = go.Figure()\n",
    "roc_fig.update_layout(title_text='ROC Comparison')\n",
    "roc_fig.add_trace(go.Scatter(x=fpr,y=tpr,name=f'Naive Bayes ROC, AUC = {round(roc_auc_score_nb,2)}',mode='lines'))\n",
    "roc_fig.add_trace(go.Scatter(x=fpr_lr,y=tpr_lr,name=f'Logistic Regression ROC, AUC = {round(roc_auc_score_lr,2)}',mode='lines+lines'))\n",
    "roc_fig.add_trace(go.Scatter(x=[0,1],y=[0,1], name='k--', line=dict(color='seagreen', width=4, dash='dot'), mode='lines+lines+lines'))\n",
    "roc_fig.update_layout(xaxis_title=\"False Positive Rate\", yaxis_title=\"True Positive Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4dae1-d411-4475-b198-9fd4a5e34442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash import JupyterDash\n",
    "app = JupyterDash(external_stylesheets=[dbc.themes.BOOTSTRAP], suppress_callback_exceptions=True)\n",
    "app.title = \"Sentiment140 dashboard\"\n",
    "\n",
    "# the style arguments for the sidebar. We use position:fixed and a fixed width\n",
    "SIDEBAR_STYLE = {\n",
    "    \"position\": \"fixed\",\n",
    "    \"top\": 0,\n",
    "    \"left\": 0,\n",
    "    \"bottom\": 0,\n",
    "    \"width\": \"25rem\",\n",
    "    \"padding\": \"2rem 1rem\",\n",
    "    \"background-color\": \"#f8f9fa\",\n",
    "}\n",
    "\n",
    "# the styles for the main content position it to the right of the sidebar and\n",
    "# add some padding.\n",
    "CONTENT_STYLE = {\n",
    "    \"margin-left\": \"25rem\",\n",
    "    \"margin-right\": \"2rem\",\n",
    "}\n",
    "\n",
    "sidebar = html.Div(\n",
    "    [\n",
    "        html.H2(\"Sentiment140 dataset\", className=\"display-4\"),\n",
    "        html.Hr(),\n",
    "        html.P(\n",
    "            \"Get some insights into Sentiment140's dataset.\", className=\"lead\"\n",
    "        ),\n",
    "        dbc.Nav(\n",
    "            [\n",
    "                dbc.NavLink(\"Dataset\", href=\"/\", active=\"exact\"),\n",
    "                dbc.NavLink(\"Word distribution\", href=\"/page-1\", active=\"exact\"),\n",
    "                dbc.NavLink(\"Evaluation\", href=\"/page-2\", active=\"exact\"),\n",
    "            ],\n",
    "            vertical=True,\n",
    "            pills=True,\n",
    "        ),\n",
    "    ],\n",
    "    style=SIDEBAR_STYLE,\n",
    ")\n",
    "\n",
    "content = html.Div(id=\"page-content\", style=CONTENT_STYLE)\n",
    "firstPage= html.P(html.Div(className='first', \n",
    "                           children=[\n",
    "                               html.Div(className='first_page', \n",
    "                                        children = [dcc.Graph(id='pos_neg_graph',figure =px.histogram(df_train_cleaned, x=\"polarity\", color='polarity',title=\"Distribution of negative and positive tweets of Sentiment140's dataset\"))])]))\n",
    "\n",
    "distributionPage = html.P(html.Div(className='distr',children=[dcc.Dropdown(id=\"polarity-selector\", options=[{'label': 'Positive', 'value': 'Positive'},{'label': 'Negative', 'value': 'Negative'}], value='Positive'),  html.Div(className='eight columns div-for-charts bg-grey',\n",
    "                                           children = [dcc.Graph(id='graph'),\n",
    "                                            html.H2(\"Wordcloud\"),\n",
    "                                            html.Img(id='image',alt='image', style={'width':'1100px', 'height':'auto'})]\n",
    "                                          )\n",
    "                               ]) \n",
    "                                  )\n",
    "\n",
    "evaluationPage = html.P(html.Div(className='ev',\n",
    "                                 children=[dcc.Graph(id='roc_graph',figure = roc_fig),\n",
    "                                           html.Hr(),\n",
    "                                           html.H3(\"Logistic Regression Model\"),\n",
    "                                           html.P(),\n",
    "                                           html.Img(id='report_lr',alt='image', src=\"assets/ClassificationReport_LR.png\"),\n",
    "                                           html.Img(id='matrix_lr',alt='image', src=\"assets/ConfusionMatrix_LR.png\", style={'width':'800px', 'height':'auto'}),\n",
    "                                           html.Hr(),\n",
    "                                           html.H3(\"Naive Bayes Model\"),\n",
    "                                           html.P(),\n",
    "                                           html.Img(id='report_nb',alt='image', src=\"assets/ClassificationReport_NB.png\"),\n",
    "                                           html.Img(id='matrix_nb',alt='image', src=\"assets/ConfusionMatrix_NB.png\", style={'width':'800px', 'height':'auto'}),\n",
    "                                          ]))\n",
    "app.layout = html.Div([dcc.Location(id=\"url\"), sidebar, content])\n",
    "\n",
    "@app.callback(Output(\"page-content\", \"children\"), [Input(\"url\", \"pathname\")])\n",
    "def render_page_content(pathname):\n",
    "    if pathname == \"/\":\n",
    "        return firstPage;\n",
    "    elif pathname == \"/page-1\":\n",
    "        return distributionPage;\n",
    "    elif pathname == \"/page-2\":\n",
    "        return evaluationPage;\n",
    "    # If the user tries to reach a different page, return a 404 message\n",
    "    return html.Div(\n",
    "        [\n",
    "            html.H1(\"404: Not found\", className=\"text-danger\"),\n",
    "            html.Hr(),\n",
    "            html.P(f\"The pathname {pathname} was not recognised...\"),\n",
    "        ],\n",
    "        className=\"p-3 bg-light rounded-3\",\n",
    "    )\n",
    "\n",
    "@app.callback(Output(\"image\", \"src\"),Input(\"polarity-selector\", \"value\") )\n",
    "def make_figure(selected):\n",
    "    if (selected=='Positive'):\n",
    "        return \"assets/wordcloud_pos.png\"\n",
    "    else: \n",
    "        return \"assets/wordcloud_neg.png\"\n",
    "\n",
    "    \n",
    "\n",
    "@app.callback(Output(\"graph\", \"figure\"),Input(\"polarity-selector\", \"value\") )\n",
    "def make_figure(selected):\n",
    "    if (selected=='Positive'):\n",
    "        return px.histogram(\n",
    "               df_top50_pos\n",
    "               ,x=\"Word\"\n",
    "               ,y=\"Count\"\n",
    "               ,log_y=True\n",
    "                ,title=\"Distribution of the top 50 most used words in positive tweets\",\n",
    "             labels={\n",
    "                     \"Word\": \"Word\",\n",
    "                     \"sum of Count\": \"Frequency\",\n",
    "                 }\n",
    "               )  \n",
    "    else: \n",
    "        return px.histogram(\n",
    "               df_top50_neg\n",
    "               ,x=\"Word\"\n",
    "               ,y=\"Count\"\n",
    "               ,log_y=True\n",
    "            ,title=\"Distribution of the top 50 most used words in negative tweets\",\n",
    "      labels={\n",
    "                     \"Word\": \"Word\",\n",
    "                     \"sum of Count\": \"Frequency\",\n",
    "                 }\n",
    "               )\n",
    "\n",
    "\n",
    "app.run_server(mode='external', port = 8090, dev_tools_ui=True, dev_tools_hot_reload=True, threaded=True)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f2b7c-c7ec-4580-90bf-6cbca43d0205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigDataScientist",
   "language": "python",
   "name": "bigdatascientist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
